import pandas as pd
import numpy as np
from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
import os

# ============================================
# 0) ì„¤ì •ê°’
# ============================================

DATASET = "/home/ice06/project/secure/mrmr_test/dataset/Dataset.csv"
OUTPUT_DIR = "/home/ice06/project/secure/mrmr_test/dataset/new"

# ë¼ë²¨ë¡œ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ë“¤(ê¸°ì—¬ë„ì—ì„œ ì œì™¸)
LABEL_COLS = [
    "NST_M_Label", "NST_B_Label",
    "IT_M_Label",  "IT_B_Label"
]

# feature selectionì— ì‚¬ìš©í•  ë¼ë²¨ ê°’ (ì˜ˆ: multi-classì˜ ì¼ë¶€ë§Œ ì‚¬ìš©)
ALLOWED_LABELS = ["Normal", "ddos", "ip-scan", "port-scan"]  # ë„ˆê°€ ì›í•˜ëŠ” ë¼ë²¨ subset

os.makedirs(OUTPUT_DIR, exist_ok=True)

# MISS íŒŒë¼ë¯¸í„°
N_BOOTSTRAP = 30
SAMPLE_FRAC = 0.7
TOP_K_EACH_ROUND = 30
PROB_THRESHOLD = 0.7
RANDOM_STATE = 42

# ============================================
# 1) ì›ë³¸ ë°ì´í„° ë¡œë“œ
# ============================================
print("ğŸ“‚ Loading dataset...")
df_full = pd.read_csv(DATASET).fillna(0)

# ============================================
# 2) feature selectionìš© ì„œë¸Œì…‹ ë§Œë“¤ê¸°
#    â†’ ë”± í•˜ë‚˜ì˜ ë¼ë²¨ ì»¬ëŸ¼(NST_M_Label) ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
# ============================================
filter_label = "NST_M_Label"

df = df_full[df_full[filter_label].isin(ALLOWED_LABELS)].reset_index(drop=True)

print(f"ğŸ¯ Feature selection using rows where {filter_label} in {ALLOWED_LABELS}")
print(f"- Original samples: {len(df_full)}")
print(f"- Filtered samples: {len(df)}")

# ============================================
# 3) feature ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
# ============================================

# ë¼ë²¨ ì»¬ëŸ¼ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ìˆ«ìí˜• featureë§Œ ì‚¬ìš©
feature_df = df.drop(columns=LABEL_COLS, errors='ignore').select_dtypes(include=[np.number])

feature_names = feature_df.columns.tolist()
X = feature_df.values

# ë¼ë²¨ ì¸ì½”ë”© (MISSì—ì„œ ì‚¬ìš©)
y_raw = df[filter_label].astype(str)
le = LabelEncoder()
y = le.fit_transform(y_raw)

print(f"- Total candidate features: {len(feature_names)}")

# ============================================
# 4) MISS ì•Œê³ ë¦¬ì¦˜ ì •ì˜
# ============================================

def miss_feature_selection(
    X, y, feature_names,
    n_bootstrap=30,
    sample_frac=0.7,
    top_k_each_round=30,
    prob_threshold=0.7,
    random_state=42,
):
    n_samples, n_features = X.shape
    select_counts = np.zeros(n_features, dtype=int)
    mi_sums = np.zeros(n_features)

    rng = np.random.RandomState(random_state)

    print("ğŸš€ Running MISS (Stability + Mutual Information)")
    for b in tqdm(range(n_bootstrap)):
        idx = rng.choice(n_samples, size=int(n_samples * sample_frac), replace=True)
        X_b = X[idx]
        y_b = y[idx]

        mi = mutual_info_classif(
            X_b, y_b, discrete_features=False,
            random_state=rng.randint(0, 99999)
        )

        top_k = min(top_k_each_round, n_features)
        top_idx = np.argsort(mi)[::-1][:top_k]

        select_counts[top_idx] += 1
        mi_sums += mi

    selection_prob = select_counts / n_bootstrap
    avg_mi = mi_sums / n_bootstrap

    result_df = pd.DataFrame({
        "feature": feature_names,
        "select_count": select_counts,
        "selection_prob": selection_prob,
        "avg_mi": avg_mi
    }).sort_values(
        by=["selection_prob", "avg_mi"],
        ascending=[False, False]
    ).reset_index(drop=True)

    selected_df = result_df[result_df["selection_prob"] >= prob_threshold]

    if len(selected_df) == 0:
        print("âš ï¸ No features passed threshold â†’ fallback to top 20")
        selected_df = result_df.head(20)

    return selected_df["feature"].tolist(), result_df, selected_df

# ============================================
# 5) MISS ì‹¤í–‰
# ============================================
selected_features, result_df, selected_df = miss_feature_selection(
    X, y, feature_names,
    n_bootstrap=N_BOOTSTRAP,
    sample_frac=SAMPLE_FRAC,
    top_k_each_round=TOP_K_EACH_ROUND,
    prob_threshold=PROB_THRESHOLD,
    random_state=RANDOM_STATE
)

print("\nâœ… Selected Features:")
for f in selected_features:
    print("-", f)

# ============================================
# 6) ê²°ê³¼ ì €ì¥
# ============================================
result_df.to_csv(os.path.join(OUTPUT_DIR, "miss_feature_scores.csv"), index=False)
selected_df.to_csv(os.path.join(OUTPUT_DIR, "miss_selected_features.csv"), index=False)

# ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒëœ í”¼ì²˜ë§Œ ë‚¨ê¸°ê¸° (ë¼ë²¨ì€ ì „ë¶€ ìœ ì§€)
df_reduced = df_full[selected_features + LABEL_COLS]
df_reduced.to_csv(os.path.join(OUTPUT_DIR, "Dataset_miss_selected.csv"), index=False)

print("ğŸ’¾ Saved Dataset_miss_selected.csv")
